{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph cut.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPL03kRdxZwEUey1Mzo4cPK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgL-MTSLt_d1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "s_data = pd.read_csv(\"subjectivity_data.csv\", index_col=0)\n",
        "data = pd.read_csv(\"data.csv\", index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k96rDkf9bX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(text, min_count=4):\n",
        "  '''\n",
        "  Takes in a 2D list of words and returns \n",
        "  set of words occuring min_count or more times\n",
        "  '''\n",
        "  wl = []\n",
        "  for i in text:\n",
        "    wl += i\n",
        "  counts = Counter(wl)\n",
        "  \n",
        "  vocab = set([i if j >= min_count else '' for i,j in counts.items()])\n",
        "  if '' in vocab:\n",
        "    vocab.remove('')\n",
        "  return vocab, counts\n",
        "\n",
        "def process(text, vocab):\n",
        "  '''\n",
        "  Takes in a Series of texts and vocabulary and returns a dataframe\n",
        "  with Vocabulary as columns and 1 / 0 as values indicating\n",
        "  the presence of word in the list\n",
        "  '''\n",
        "  text = list(text.apply(lambda x: Counter(set(x) & vocab)))\n",
        "  return pd.DataFrame(text).fillna(0).astype('bool')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdjJJlzR9qPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_proc = s_data.copy()\n",
        "classes = s_proc['class']\n",
        "s_proc.text = s_proc.text.apply(lambda x: x.replace('  ', ' ').split())\n",
        "vocab, _ = build_vocab(s_proc.text, 5)\n",
        "s_proc = process(s_proc.text, vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXsv3Iytz3Px",
        "colab_type": "code",
        "outputId": "f245071c-2324-4743-bf97-f09f82cba13c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(10, random_state=5, shuffle=True)\n",
        "acc = []\n",
        "for train, test in kf.split(s_proc, classes):\n",
        "  model = MultinomialNB()\n",
        "  model.fit(s_proc.iloc[train], classes.iloc[train])\n",
        "  acc.append(model.score(s_proc.iloc[test], classes.iloc[test]))\n",
        "print(f\"10-fold accuracy for ExtractNB: {np.mean(acc) * 100:.2f}\")\n",
        "\n",
        "extractNB = MultinomialNB()\n",
        "extractNB.fit(s_proc, classes)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10-fold accuracy for ExtractNB: 91.71\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmq07Gv-EPwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "def negateWords(wordlist):\n",
        "  '''\n",
        "  Add the tag\n",
        "  'NOT' to every word between a negation word (“not”,\n",
        "  “isn’t”, “didn’t”, etc.) and the first punctuation\n",
        "  mark following the negation word.\n",
        "  '''\n",
        "  new_list = []\n",
        "  i = 0\n",
        "  while i < len(wordlist):\n",
        "    if wordlist[i] == \"not\" or \"n't\" in wordlist[i]:\n",
        "      new_list.append(wordlist[i])\n",
        "      i += 1\n",
        "      while i < len(wordlist) and wordlist[i] not in string.punctuation:\n",
        "        new_list.append(\"NOT_\" + wordlist[i])\n",
        "        i += 1\n",
        "    if i < len(wordlist):\n",
        "      new_list.append(wordlist[i])\n",
        "    i += 1\n",
        "  return new_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1H8xp4pOs0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform(sents, vocab=list(s_proc.columns)):\n",
        "  '''\n",
        "  Transform senteces into boolean tuples\n",
        "  '''\n",
        "  vects = []\n",
        "  for sent in sents:\n",
        "    s = set(sent.split())\n",
        "    vector = [i in s for i in vocab]\n",
        "    vects.append(vector)\n",
        "  return vects\n",
        "\n",
        "def subjectivity(translist, model=extractNB):\n",
        "  '''\n",
        "  Indices of sentences ordered based on their subjectivity (descending)\n",
        "  '''\n",
        "  return np.argsort(model.predict_proba(translist)[:, list(model.classes_).index('Obj')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5rvXGaRHuT9",
        "colab_type": "code",
        "outputId": "47babfeb-78a9-4cd7-9d62-161a8da962fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "extract_data = data.copy()\n",
        "extract_data.text = extract_data.text.apply(lambda x: x.split('\\n'))\n",
        "extract_data['transformed'] = extract_data.text.apply(transform)\n",
        "extract_data.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>transformed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[synopsis : the president of a company wants t...</td>\n",
              "      <td>neg</td>\n",
              "      <td>[[False, False, False, False, True, False, Fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[okay , bear with me y'all , cause first off i...</td>\n",
              "      <td>neg</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[around the end of 1998 , a japanese cartoon c...</td>\n",
              "      <td>neg</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[the story of us , a rob reiner film , is the ...</td>\n",
              "      <td>pos</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[when i was nine , i started buying the cooles...</td>\n",
              "      <td>neg</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                        transformed\n",
              "0  [synopsis : the president of a company wants t...  ...  [[False, False, False, False, True, False, Fal...\n",
              "1  [okay , bear with me y'all , cause first off i...  ...  [[False, False, False, False, False, False, Fa...\n",
              "2  [around the end of 1998 , a japanese cartoon c...  ...  [[False, False, False, False, False, False, Fa...\n",
              "3  [the story of us , a rob reiner film , is the ...  ...  [[False, False, False, False, False, False, Fa...\n",
              "4  [when i was nine , i started buying the cooles...  ...  [[False, False, False, False, False, False, Fa...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DunbS5Iepj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kfoldAccuracy(X, y, k=3, model=MultinomialNB()):\n",
        "  '''\n",
        "  Trains the model and returns the average k-fold cross validation accuracy in %\n",
        "  '''\n",
        "  kf2 = KFold(k, random_state=0, shuffle=True)\n",
        "  acc = []\n",
        "  print(\"\\tTraining ...\")\n",
        "  for train, test in kf.split(X, y):\n",
        "    model.fit(X.iloc[train], y.iloc[train])\n",
        "    acc.append(model.score(X.iloc[test], y.iloc[test]))\n",
        "  return np.mean(acc) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaCf_3plL874",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import networkx as nx\n",
        "\n",
        "def mincutExtract(probs, classes=list(extractNB.classes_), c=0.5, T=2, f=lambda d: 1/d**2):\n",
        "  '''\n",
        "  Takes in an array probabilities that a sentence is subjective vs objective\n",
        "  and returns the indexes of subjective sentences, based on minimum graph cut partitioning\n",
        "  '''\n",
        "  G = nx.Graph()\n",
        "  G.add_nodes_from(['S', 'T'])\n",
        "  G.add_nodes_from(range(len(probs)))\n",
        "  for n in G.nodes():\n",
        "    if n != 'S' and n != 'T':\n",
        "      G.add_edge('S', n, capacity=probs[n][classes.index('Subj')])\n",
        "      G.add_edge('T', n, capacity=probs[n][classes.index('Obj')])\n",
        "      for n2 in G.nodes():\n",
        "        if n2 != 'S' and n2 != 'T' and n2 > n:\n",
        "          G.add_edge(n, n2, capacity=f(n2 - n) * c if n2 - n <= T else 0)\n",
        "  return list(nx.minimum_cut(G, 'S', 'T')[1][0] - {'S'})\n",
        "\n",
        "extract_data['extracts'] = extract_data.transformed.apply(lambda x: mincutExtract(extractNB.predict_proba(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-oARGyNXRIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = []\n",
        "for i in range(len(extract_data.text)):\n",
        "  sents = extract_data.text[i]\n",
        "  idxs = extract_data.extracts[i]\n",
        "  sents = np.array(sents)\n",
        "  review = \" \".join(sents[idxs]).replace(\"  \", \" \").split()\n",
        "  reviews.append(review)\n",
        "\n",
        "reviews = pd.Series(reviews)\n",
        "X = process(reviews, build_vocab(reviews)[0])\n",
        "y = extract_data['class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6-SipfhaefN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d3bcb60e-f41b-4759-e047-d5f31466adc5"
      },
      "source": [
        "print(f\"Naive Bayes Accuracy: {kfoldAccuracy(X, y, k=10):.2f}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTraining ...\n",
            "Naive Bayes Accuracy: 85.60\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}